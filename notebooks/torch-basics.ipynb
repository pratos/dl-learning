{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1945ce-f4f3-433b-98b2-8c7670dc1ba1",
   "metadata": {},
   "source": [
    "In the context of machine learning and particularly in classification problems, \"logits\" usually refer to the vector of raw (non-normalized) predictions that a classification model generates, which are then typically passed to a normalization function. If the normalization function is the softmax function, the model is said to be predicting the \"logits\".\n",
    "\n",
    "For example, suppose we have a model for classifying images into 3 categories. The output layer of this model might be a fully connected layer with 3 nodes, one for each category. The values produced by this layer, before any kind of normalization like softmax, are the logits.\n",
    "\n",
    "The term \"logits\" actually comes from the log-odds, in the context of logistic regression. In logistic regression, the logit function, which is the inverse of the logistic sigmoid function, takes a probability value between 0 and 1 and transforms it into a value between negative infinity and positive infinity.\n",
    "\n",
    "However, in modern usage in the context of deep learning, \"logits\" often simply refer to the output of the last layer of a network before the application of an activation function.\n",
    "\n",
    "Here's a basic illustration using Python and PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcc5a514-f498-407b-84ac-eb6c52196abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0524,  0.1751, -0.3278], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# suppose we have a model with 3 output classes\n",
    "model = nn.Linear(10, 3)\n",
    "\n",
    "# suppose we have some input vector x\n",
    "x = torch.rand(10)\n",
    "\n",
    "# we can compute the logits as follows\n",
    "logits = model(x)\n",
    "\n",
    "print(logits)  # these are the logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a47c80d-471c-4f46-b6aa-7eaba2c5bf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=3, bias=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21d9a0c-f436-451c-a182-4999e603dc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8137, 0.2957, 0.8366, 0.4001, 0.3475, 0.3923, 0.0906, 0.8936, 0.8353,\n",
       "        0.3907])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc53bfbd-31eb-463c-a854-74519255d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3553, 0.4017, 0.2429], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "probabilities = torch.nn.functional.softmax(logits, dim=0)\n",
    "\n",
    "print(probabilities)  # these are the probabilities associated with each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3c0b5-32a2-46c0-9855-0754a3f243d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
